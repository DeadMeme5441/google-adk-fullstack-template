# ==============================================================================
# Google ADK Template Configuration
# ==============================================================================

# ------------------------------------------------------------------------------
# Agent Configuration
# ------------------------------------------------------------------------------
# Customize your agent's basic properties
AGENT_NAME=my_assistant
AGENT_MODEL=gemini-2.0-flash-exp
AGENT_DESCRIPTION=A helpful AI assistant that can search the web and provide intelligent responses to user queries.

# ------------------------------------------------------------------------------
# Model Provider Configuration
# ------------------------------------------------------------------------------
# Choose your model provider:
# - 'gemini': Use Google Gemini models (default, recommended)
# - 'litellm': Use other providers like OpenAI, Anthropic, local models, etc.
MODEL_PROVIDER=gemini

# ------------------------------------------------------------------------------
# Google Gemini Models Configuration
# ------------------------------------------------------------------------------
# Required when MODEL_PROVIDER=gemini

# For Google AI Studio (easiest setup):
GOOGLE_GENAI_USE_VERTEXAI=False
GOOGLE_API_KEY=your_google_api_key_here

# For Google Cloud Vertex AI (production/enterprise):
# GOOGLE_GENAI_USE_VERTEXAI=True
# GOOGLE_CLOUD_PROJECT=your-gcp-project-id
# GOOGLE_CLOUD_LOCATION=us-central1
# GOOGLE_API_KEY=your_vertex_ai_api_key_or_leave_blank_for_adc

# Available Gemini models:
# - gemini-2.0-flash-exp (latest experimental)
# - gemini-2.0-flash (stable)
# - gemini-1.5-pro (powerful, larger context)
# - gemini-1.5-flash (fast, efficient)

# ------------------------------------------------------------------------------
# LiteLLM Configuration (for non-Google models)
# ------------------------------------------------------------------------------
# Required when MODEL_PROVIDER=litellm
# Uncomment and set the API keys for providers you want to use

# OpenAI Models
# OPENAI_API_KEY=your_openai_api_key_here
# Examples: openai/gpt-4o, openai/gpt-4o-mini, openai/gpt-3.5-turbo

# Anthropic Claude Models  
# ANTHROPIC_API_KEY=your_anthropic_api_key_here
# Examples: anthropic/claude-3-sonnet-20240229, anthropic/claude-3-haiku-20240307

# Cohere Models
# COHERE_API_KEY=your_cohere_api_key_here
# Examples: cohere/command-r-plus, cohere/command-r

# Other LiteLLM providers (see https://docs.litellm.ai/docs/providers)
# Add API keys as needed for other providers

# ------------------------------------------------------------------------------
# Local Models Configuration
# ------------------------------------------------------------------------------
# For running models locally with Ollama, vLLM, etc.

# Ollama (local models)
# OLLAMA_API_BASE=http://localhost:11434
# Examples with AGENT_MODEL: ollama_chat/llama3.1, ollama_chat/mistral

# vLLM or other OpenAI-compatible endpoints
# OPENAI_API_BASE=http://localhost:8000/v1
# OPENAI_API_KEY=anything
# Examples with AGENT_MODEL: openai/model_name_on_your_endpoint

# LiteLLM Debug (enable for troubleshooting model connections)
LITELLM_DEBUG=False

# ------------------------------------------------------------------------------
# Server Configuration
# ------------------------------------------------------------------------------
HOST=0.0.0.0
PORT=8000

# Logging level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# Enable ADK Web UI for testing
SERVE_WEB_INTERFACE=True

# Enable hot reload during development
RELOAD_AGENTS=True

# CORS origins (adjust for your frontend URL)
# ALLOWED_ORIGINS=["http://localhost:3000", "http://localhost:5173"]

# ------------------------------------------------------------------------------
# Authentication Configuration
# ------------------------------------------------------------------------------
# JWT-based authentication system

# JWT Secret Key - CHANGE THIS IN PRODUCTION!
# Generate a secure random key: python -c "import secrets; print(secrets.token_urlsafe(32))"
JWT_SECRET_KEY=your-secret-key-change-this-in-production

# JWT token expiry (in days)
JWT_ACCESS_TOKEN_EXPIRE_DAYS=7

# JWT algorithm (HS256 is recommended for single-server deployments)
JWT_ALGORITHM=HS256

# ------------------------------------------------------------------------------
# MongoDB Session Service Configuration
# ------------------------------------------------------------------------------
# Persistent conversation storage

# Local MongoDB
MONGO_URL=mongodb://localhost:27017
MONGO_DB_NAME=adk_sessions
MONGO_COLLECTION_NAME=sessions

# MongoDB Atlas (cloud)
# MONGO_URL=mongodb+srv://username:password@cluster.mongodb.net
# MONGO_DB_NAME=adk_sessions
# MONGO_COLLECTION_NAME=sessions

# ------------------------------------------------------------------------------
# S3 Artifact Service Configuration
# ------------------------------------------------------------------------------
# File storage for agent artifacts

S3_BUCKET_NAME=my-agent-artifacts

# AWS S3 (production)
# AWS_ACCESS_KEY_ID=your_aws_access_key
# AWS_SECRET_ACCESS_KEY=your_aws_secret_key  
# AWS_REGION=us-east-1

# MinIO (local S3-compatible storage for development)
# S3_ENDPOINT_URL=http://localhost:9000
# AWS_ACCESS_KEY_ID=minioadmin
# AWS_SECRET_ACCESS_KEY=minioadmin
# AWS_REGION=us-east-1

# Other S3-compatible services (DigitalOcean Spaces, Wasabi, etc.)
# S3_ENDPOINT_URL=https://your-service-endpoint
# AWS_ACCESS_KEY_ID=your_access_key
# AWS_SECRET_ACCESS_KEY=your_secret_key
# AWS_REGION=your_region

# ==============================================================================
# Getting Started
# ==============================================================================
# 
# 1. Copy this file to .env
# 2. Choose your model provider (gemini or litellm)
# 3. Set the appropriate API keys
# 4. Configure MongoDB and S3 endpoints
# 5. Customize your agent name, model, and description
# 6. Run: python main.py
#
# For detailed setup instructions, see README.md
#